{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 신경망 학습\n",
    "## 데이터에서 학습한다.\n",
    "신경망의 특징은 데이터를 보고 학습할 수 있다는 점이다. 데이터에서 학습한다는 것은 가중치 매개변수의 값을 데이터를 보고 자동으로 결정한다는 뜻이다.\n",
    "매개변수를 수작업으로 정한다는것은 아예 불가능하다.\n",
    "데이터로부터 매개변수의 값을 정하는 방법에 대해 설명하고 MNIST 데이터셋의 손글씨 숫자를 학습하는 코드를 구현해보자.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 주도 학습\n",
    "5라는 숫자를 제대로 분류하는 프로그램을 직접 고안해 설계하기란 의외로 어려운 문제임을 알 수 있다.\n",
    "사람이라면 어렵지 않게 인식하지만, 그 안에 숨은 규칙성을 명확한 로직으로 풀기가 만만치 않다.\n",
    "사람마다 버릇이 달라 5를 특징짓는 규칙을 찾기도 쉽지 않고 시간도 오래 걸릴 것 같다는 느낌이 든다.\n",
    "\n",
    "이미지에서 특징을 추출하고 그 특징의 패턴을 기계학습 기술로 학습하는 방법이 있다.\n",
    "여기서 말하는 특징은 입력 데이터(입력이미지)에서 본질적인 데이터(중요한 데이터)를 정확하게 추출할 수 있도록 설계된 변환기를 가리킨다.\n",
    "이미지의 특징은 보통 벡터로 기술하고, 컴퓨터 비전 분야에서는 SIFT, SURF, HOG 등의 특징을 많이 사용한다.\n",
    "이런 특징을 사용하여 이미지 데이터를 벡터로 변환하고, 변환된 벡터를 가지고 지도 학습 방식의 대표 분류 기법인 SVM,KNN 등으로 학습할 수 있다.\n",
    "\n",
    "이와 같은 기계학습에서는 모아진 데이터로부터 규칙을 찾아내는 역할을 기계가 담당한다.\n",
    "무로부터 알고리즘을 설계하는 것보다 효율이 높아 문제를 해결해야 하는 사람의 부담도 덜어준다.\n",
    "다만, 이미지를 벡터로 변환할 때 사용하는 특징은 여전히 사람이 설계하는 것임에 주의해야 한다.\n",
    "이 말은 문제에 적합한 특징을 쓰지 않으면(혹은 특징을 설계하지 않으면) 좀 처럼 좋은 결과를 얻을 수 없다는 뜻이다.\n",
    "![nn](../images/chap4/image1.png)\n",
    "\n",
    "위의 그림과 같이 신경망은 이미지를 있는 그대로 학습한다. 두 번째 접근 방식에서는 특징을 사람이 설계했지만, 신경망은 이미지에 포함된 중요한 특징까지도 기계가 스스로 학습할 것이다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 훈련 데이터와 시험 데이터\n",
    "기계학습 문제는 데이터를 훈련데이터와 시험데이터로 나눠 학습과 실험을 수행하는 것이 일반적이다.\n",
    "우선 훈련 데이터만 사용하여 학습하면서 최적의 매개변수를 찾는다.\n",
    "그런 다음 시험 데이터를 사용하여 앞서 훈련한 모델의 실력을 평가하는 것이다.\n",
    "훈련 데이터와 시험데이터를 나누는 이유는 우리가 원하는 것은 범용적으로 사용할수 있는 모델이기 때문이다.\n",
    "이 범용 능력을 제대로 평가하기 위해 훈련 데이터와 시험 데이터를 분리하는것이다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 손실 함수\n",
    "신경망 학습에서는 현재의 상태를 하나의 지표로 표현한다. 그리고 그 지표를 가장 좋게 만들어주는 가중치 매개변수의 값을 탐색하는 것이다.\n",
    "하나의 지표를 기준으로 최적의 매개변수 값을 탐색한다. 신경망 학습에서 사용하는 지표는 손실함수라고 한다.\n",
    "손실함수는 임의의 함수를 사용할 수도 있지만 일반적으로는 오차제곱합과 교차 엔트로피 오차를 사용한다.\n",
    "\n",
    "> 손실함수는 신경망 성능의 나쁨을 나타내는 지표로, 현재의 신경망이 훈련 데이터를 얼마나 잘 처리하지 못하느냐를 나타낸다.\n",
    "성능 나쁨을 지표로 한다니 무언가 부자연스럽다고 생각할지 모르지만, 손실함수에 마이너스만 곱하면 얼마나 나쁘지 않나, 즉 얼마나 좋으냐라는 지표로 변신한다.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 오차 제곱합\n",
    "$$ E = \\frac{1}{2} \\sum_k(y_k-t_k)^2 $$\n",
    "여기서 $y_k$ 는 신경망의 출력(신경망이 추정한 값), $t_k$ 는 정답 레이블, $k$ 는 데이터의 차원 수를 나타낸다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sum_squares_error(y,t):\n",
    "    return 0.5 * np.sum((y-t) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5975"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0] # 정답은 2\n",
    "# 예 1 : '2' 일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
    "\n",
    "sum_squares_error(np.array(y),np.array(t))\n",
    "# 예 2 : '7'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
    "sum_squares_error(np.array(y),np.array(t))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 교차 엔트로피 오차\n",
    "또 다른 손실함수로써 교차 엔트로피 오차도 자주 이용한다.\n",
    "$$ E = -\\sum_k t_k log_e y_k $$\n",
    "$y_k$ 는 신경망의 출력, $t_k$ 는 정답 레이블이다.\n",
    "또 $t_k$ 는 정답에 해당하는 인덱스의 원소만 1이고 나머지는 0이다.(원-핫 인코딩)\n",
    "실질적으로 정답일 때의 추정($t_k$가 1일때의 $y_k$)의 자연로그를 계산하는 식이 된다.\n",
    "예를들어 정답레이블은 2가 정답이라하고 이때의 신경망 출력이 0.6 이라면 교차 엔트로피 오차는 0.51이 된다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "2.302584092994546"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0] # 정답은 2\n",
    "# 예 1 : '2' 일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
    "cross_entropy_error(np.array(y),np.array(t))\n",
    "\n",
    "\n",
    "\n",
    "# 예 2 : '7'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
    "cross_entropy_error(np.array(y),np.array(t))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 미니 배치 학습\n",
    "기계학습 문제는 훈련 데이터를 사용해 학습한다. 더 구체적으로 말하면 훈련 데이터에 대한 손실 함수의 값을 구하고, 그 값을 최대한 줄여주는 매개변수를 찾아낸다.\n",
    "이렇게 하려면 모든 훈련 데이터를 대상으로 손실 함수 값을 구해야 한다. 즉 훈련데이터가 100개 있으면 그로부터 계산한 100개의 손실 함수 값들의 합을 지표로 삼는것이다.\n",
    "교차 엔트로피의 경우 다음과 같다.\n",
    "$$ E = -\\frac{1}{N}\\sum_n\\sum_kt_{nk}\\log y_{nk} $$\n",
    "\n",
    "빅데이터 수준이 되면 데이터의 수는 수백만에서 수천만도 넘는 거대한 값이 되기도 한다. 이많은 데이터를 대상으로 일일이 손실함수를 계산하는건 현실적이지 않다.\n",
    "이런경우 데이터 일부를 추려 전체의 근사치로 이용할수 잇다. 신경망 학습에서도 훈련 데이터로부터 일부만 골라 학습을 수행한다.\n",
    "일부를 미니배치라고 한다.\n",
    "가령 60000장의 훈련데이터 중에서 100장을 무작위로 뽑아 그 100장만을 사용하여 학습하는것이다.\n",
    "이러한 학습 방법을 미니배치 학습 이라고 한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### MINIST 데이터셋을 읽어오는 코드"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train,t_train),(x_test,t_test) = \\\n",
    "    load_mnist(normalize=True,one_hot_label=True)\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (배치용) 교차 엔트로피 오차 구현하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        print(t)\n",
    "        y = y.reshape(1,y.size)\n",
    "        print(y)\n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t] + 1e-7))/batch_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m x_batch \u001B[38;5;241m=\u001B[39m x_train[batch_mask]\n\u001B[0;32m      6\u001B[0m t_batch \u001B[38;5;241m=\u001B[39m t_train[batch_mask]\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28mprint\u001B[39m(cross_entropy_error(np\u001B[38;5;241m.\u001B[39marray(x_batch),np\u001B[38;5;241m.\u001B[39marray(t_batch)))\n",
      "Cell \u001B[1;32mIn[58], line 9\u001B[0m, in \u001B[0;36mcross_entropy_error\u001B[1;34m(y, t)\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(y)\n\u001B[0;32m      8\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39mnp\u001B[38;5;241m.\u001B[39msum(np\u001B[38;5;241m.\u001B[39mlog(y[np\u001B[38;5;241m.\u001B[39marange(batch_size),t] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-7\u001B[39m))\u001B[38;5;241m/\u001B[39mbatch_size\n",
      "\u001B[1;31mIndexError\u001B[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size,batch_size)\n",
    "\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
