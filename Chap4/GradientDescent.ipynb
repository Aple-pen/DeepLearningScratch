{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 경사 하강법\n",
    "기계학습 문제 대부분은 학습 단계에서 최적의 매개변수를 찾아낸다.\n",
    "신경망 역시 최적의 매개변수를 학습 시에 찾아야 한다.\n",
    "여기서 최적이란 손실 함수가 최솟값이 될 때의 매개변수 값이다. 그러나 일반적인 문제의 손실함수는 매우 복잡하다.\n",
    "매개변수 공간이 광대하여 어디가 최솟값이 되는 곳인지를 짐작할 수 없다.\n",
    "이런 상황에서 기울기를 잘 이용해 함수의 최솟값을 찾으려는 것이 경사법이다.\n",
    "\n",
    "여기에서 주의할 점은 각 지점에서 함수의 값을 낮추는 방안을 제시하는 지표가 기울기라는 것이다.\n",
    "그러나 기울기가 가리키는 곳에 정말 함수의 최솟값이 있는지, 즉 그쪽이 정말 나아갈 방향인지는 보장할 수 없다.\n",
    "실제로 복잡한 함수에서는 기울기가 가리키는 방향에 최솟값이 없는 경우가 대부분이다.\n",
    "\n",
    "기울어진 방향이 꼭 최솟값을 가리키는 것은 아니나, 그 방향으로 가야 함수의 값을 줄일 수 있다.\n",
    "그래서 최솟값이 되는 장소를 찾는 문제에서는 기울기 정보를 단서로 나아갈 방향을 정해야 한다.\n",
    "\n",
    "경사법은 현 위치에서 기울어진 방향으로 일정거리 만큼 이동한다. 그런다음 이동한 곳에서도 마찬가지로 기울기를 구하고, 또 그 기울어진 방향으로 나아가기를 반복한다.\n",
    "이렇게 해서 함수의 값을 점차 줄이는 것이 경사법이다.\n",
    "$$ x_0 = x_0 - \\eta\\frac{\\partial f}{\\partial x_0} $$\n",
    "$$ x_1 = x_1 - \\eta\\frac{\\partial f}{\\partial x_1} $$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\eta$기호(eta)는 갱신하는 양을 나타낸다. 이를 신경망 학습에서는 학습률이라고 한다. 한 번의 학습으로 얼마만큼 학습해야 할지, 즉 매개변수 값을 얼마나 갱신하느냐를 정하는 것이 학습률이다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
